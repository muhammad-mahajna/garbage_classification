{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Preprocessing for the images\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.Resize((224, 224)),  # ResNet50 expects 224x224 input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Vocabulary and tokenization for text processing\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        # Initialize with \"<unk>\" token for unknown words\n",
    "        self.word2idx = {\"<unk>\": 0}\n",
    "        self.idx2word = {0: \"<unk>\"}\n",
    "        self.idx = 1  # Start from 1 because 0 is reserved for \"<unk>\"\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "\n",
    "    def __call__(self, word):\n",
    "        # Return the index for the word or \"<unk>\" if not found\n",
    "        return self.word2idx.get(word, self.word2idx[\"<unk>\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "# Custom Dataset class for both image and text input\n",
    "class CustomImageTextDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, vocab=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.class_names = ['Black', 'Blue', 'Green', 'TTR']\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        # Collect all image file paths and corresponding labels from subfolders\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_name in self.class_names:\n",
    "            class_dir = os.path.join(self.root_dir, class_name)\n",
    "            for img_file in os.listdir(class_dir):\n",
    "                if img_file.endswith('.jpg') or img_file.endswith('.jpeg') or img_file.endswith('.png'):\n",
    "                    self.image_paths.append(os.path.join(class_dir, img_file))\n",
    "                    self.labels.append(self.class_names.index(class_name))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load the image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Extract the text from the filename (if needed)\n",
    "        img_name = os.path.basename(img_path)\n",
    "        label_text = re.sub(r'\\d+', '', img_name.split('.')[0]).strip().lower()\n",
    "        text_tokens = tokenize_text(label_text)\n",
    "\n",
    "        # Convert text tokens to indices using the vocabulary\n",
    "        text_indices = [self.vocab(token) for token in text_tokens]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(text_indices), label\n",
    "\n",
    "# Load GloVe Embeddings\n",
    "def load_glove_embeddings(glove_file, vocab):\n",
    "    embedding_dim = 100  # GloVe 100D embeddings\n",
    "    embeddings_index = {}\n",
    "\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vector\n",
    "\n",
    "    # Create the embedding matrix for our vocabulary\n",
    "    embedding_matrix = np.zeros((len(vocab), embedding_dim))\n",
    "\n",
    "    for word, idx in vocab.word2idx.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[idx] = embedding_vector\n",
    "        else:\n",
    "            embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "# Define the Model\n",
    "class ImageTextResNet50(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, pretrained_embeddings=None):\n",
    "        super(ImageTextResNet50, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet50 model for image classification\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 128)  # Replace final layer\n",
    "\n",
    "        # Use GloVe pretrained embeddings for text\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc_text = nn.Linear(hidden_dim, 128)\n",
    "\n",
    "        # Combine the features from both image and text\n",
    "        self.fc_combined = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, image, text):\n",
    "        # Forward pass through ResNet50\n",
    "        x_img = self.resnet(image)\n",
    "\n",
    "        # Forward pass through embedding + LSTM for text\n",
    "        embedded_text = self.embedding(text)\n",
    "        lstm_out, _ = self.lstm(embedded_text)\n",
    "        x_text = torch.relu(self.fc_text(lstm_out[:, -1, :]))  # Last output of LSTM\n",
    "\n",
    "        # Combine image and text features\n",
    "        x_combined = torch.cat((x_img, x_text), dim=1)\n",
    "        output = self.fc_combined(x_combined)\n",
    "        return output\n",
    "\n",
    "# Training and validation code would be as before:\n",
    "# Create DataLoaders, loss function, optimizer, etc.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
