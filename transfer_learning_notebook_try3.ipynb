{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data preparation\n",
    "# Load data\n",
    "def load_data(data_dir):\n",
    "    image_paths = []\n",
    "    texts = []\n",
    "    labels = []\n",
    "    label_map = {\"Black\": 0, \"Blue\": 1, \"Green\": 2, \"TTR\": 3}\n",
    "\n",
    "    for label_name, label_idx in label_map.items():\n",
    "        folder_path = os.path.join(data_dir, label_name)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        # Iterate through all files in the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_path = os.path.join(folder_path, filename)\n",
    "                image_paths.append(image_path)\n",
    "\n",
    "                # Use the filename as the text description, remove digits\n",
    "                file_name_no_ext, _ = os.path.splitext(filename)\n",
    "                text_description = re.sub(r'\\d+', '', file_name_no_ext.replace('_', ' '))\n",
    "                texts.append(text_description)\n",
    "\n",
    "                labels.append(label_idx)\n",
    "\n",
    "    return np.array(image_paths), np.array(texts), np.array(labels)\n",
    "\n",
    "# Function to detect the base directory depending on the PC\n",
    "def detect_base_directory():\n",
    "    possible_dirs = [\n",
    "        r\"/work/TALC/enel645_2024f/garbage_data\",  # Directory on TALC cluster\n",
    "        r\"../../data/enel645_2024f/garbage_data\"  # Directory on LAPTOP\n",
    "    ]\n",
    "\n",
    "    for base_dir in possible_dirs:\n",
    "        if os.path.exists(base_dir):\n",
    "            print(f\"Using base directory: {base_dir}\")\n",
    "            return base_dir\n",
    "\n",
    "    raise ValueError(\"No valid base directory found.\")\n",
    "\n",
    "# Base directory detection\n",
    "base_dir = detect_base_directory()\n",
    "\n",
    "# Define the train, val, and test directories\n",
    "train_dir = os.path.join(base_dir, \"CVPR_2024_dataset_Train\")\n",
    "val_dir = os.path.join(base_dir, \"CVPR_2024_dataset_Val\")\n",
    "test_dir = os.path.join(base_dir, \"CVPR_2024_dataset_Test\")\n",
    "\n",
    "train_image_paths, train_texts, train_labels = load_data(train_dir)\n",
    "val_image_paths, val_texts, val_labels = load_data(val_dir)\n",
    "test_image_paths, test_texts, test_labels = load_data(test_dir)\n",
    "\n",
    "# Define the custom dataset\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, image_paths, texts, labels, transform=None, tokenizer=None, max_len=24):\n",
    "        self.image_paths = image_paths\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Tokenize text\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return {\n",
    "            'image': image,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = MultimodalDataset(train_image_paths, train_texts, train_labels, transform=transform, tokenizer=tokenizer)\n",
    "val_dataset = MultimodalDataset(val_image_paths, val_texts, val_labels, transform=transform, tokenizer=tokenizer)\n",
    "test_dataset = MultimodalDataset(test_image_paths, test_texts, test_labels, transform=transform, tokenizer=tokenizer)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Multimodal model combining ResNet50 and DistilBERT\n",
    "class MultimodalModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultimodalModel, self).__init__()\n",
    "        # Load pretrained ResNet50 model\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        self.resnet_feature_dim = 2048\n",
    "\n",
    "        # Load DistilBERT model\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.distilbert_feature_dim = 768\n",
    "\n",
    "        # Fully connected layers for combining features\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet_feature_dim + self.distilbert_feature_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "            \n",
    "\n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        # Extract image features\n",
    "        image_features = self.resnet(images)\n",
    "        # Extract text features\n",
    "        text_features = self.distilbert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "\n",
    "        # Concatenate image and text features\n",
    "        combined_features = torch.cat((image_features, text_features), dim=1)\n",
    "\n",
    "        # Pass through fully connected layers\n",
    "        output = self.fc(combined_features)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Hyperparameters and model setup\n",
    "num_classes = 4\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "# Label map\n",
    "label_map = {\"Black\": 0, \"Blue\": 1, \"Green\": 2, \"TTR\": 3}\n",
    "\n",
    "# Count the number of files in each class directory\n",
    "class_counts = np.zeros(len(label_map), dtype=np.int32)\n",
    "for label_name, label_idx in label_map.items():\n",
    "    folder_path = os.path.join(train_dir, label_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        class_counts[label_idx] = len([f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "# Calculate the class weights using inverse frequency\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights / class_weights.sum()  # Normalize to sum to 1\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# Print the class counts and weights\n",
    "for class_name, count, weight in zip(label_map.keys(), class_counts, class_weights):\n",
    "    print(f'Class {class_name}: {count} samples, Weight: {weight:.4f}')\n",
    "\n",
    "\n",
    "model = MultimodalModel(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        images = batch['image'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = accuracy_score(y_true, y_pred)\n",
    "    val_precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    val_recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, Val Prec: {val_precision:.4f}, Val Recall: {val_recall:.4f}')\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        torch.save(model.state_dict(), 'best_multimodal_model.pth')\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model and evaluate on the test set\n",
    "model.load_state_dict(torch.load('best_multimodal_model.pth', map_location=device))\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images = batch['image'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        outputs = model(images, input_ids, attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        test_predictions.extend(preds.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Normalize the confusion matrix by row (true labels)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_normalized, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n",
    "\n",
    "# Test set metrics\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}, Test Precision: {test_precision:.4f}, Test Recall: {test_recall:.4f}')\n",
    "\n",
    "# Calculate the accuracy for each class\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "label_map = {\"Black\": 0, \"Blue\": 1, \"Green\": 2, \"TTR\": 3}\n",
    "# Map label indices back to class names\n",
    "label_names = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# Print accuracy per class\n",
    "for i, accuracy in enumerate(class_accuracy):\n",
    "    class_name = label_names[i]\n",
    "    print(f'Accuracy for {class_name}: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistaken_indices = [i for i, (true, pred) in enumerate(zip(test_labels, test_predictions)) if true == 3 and pred == 1]\n",
    "print(f'Number of cases where \"Other\" was mistakenly identified as \"Blue\": {len(mistaken_indices)}')\n",
    "print(\"Indices of the mistakes:\", mistaken_indices)\n",
    "\n",
    "# keywords: plastic, bottle, Container, box, packaging, bag, wrapper\n",
    "# Load the image\n",
    "print(test_image_paths[mistaken_indices])\n",
    "\n",
    "image_path = test_image_paths[mistaken_indices[1]]\n",
    "\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Hide the axes\n",
    "plt.title(image_path)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
